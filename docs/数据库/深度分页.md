# 为什么 mysql 深度分页会很慢？
包括两层，server层和存储引擎层
server层：查询缓存，解析sql语句生成语法树，执行sql。在执行sql中包括预处理器，优化器和执行器。
预处理器：将查询字段展开（如select * 展开为具体字段）并检查字段是否合法
优化器：指定sql执行计划，如选择合适的索引
执行器：与存储引擎层交互，执行sql语句
存储引擎层 Engine层：如InnoDB和MyISAM。以InnoDB为例，访问B+树数据结构获取记录（聚簇索引，二级索引等的访问都在存储引擎层）

limit 是执行在server 层，而不是innodb层。
也就是说， 在server层 需要获取到 全部的 limit_cout 的结果，在发送给客户端时，才会进行limit操作。
server 层 在执行器调存储引擎api获取到一条数据时，会查看数据是否是第1000000 以后条数据，如果不是，就不会发送到客户端，只进行limit_cout 计数。
server 层 直到10001才会发送到客户端。也就是说，执行 limit m n语句的场景下， Engine层 实际上也会访问前m条数据，然后返回后n条数据。
正是因为 Engine层 limit会扫描每条记录，因此如果我们查询的字段需要回表扫描，每一次查询都会拿着age列的二级索引查到的主键值去回表，limit 1000000 就会回表1000000 次，效率极低。

## 单表场景 limit 深度分页 的优化方法 (游标)
对于LIMIT分页查询的性能优化，主要思路是利用  索引覆盖 字段定位数据，然后再取出内容
1. 子查询分页方式
```sql
SELECT * FROM tbl_works
WHERE id >= (SELECT id FROM tbl_works limit 100000, 1)
LIMIT 20  // 54ms
```
子查询分页方式，首先通过子查询和索引覆盖定位到起始位置ID，然后再取所需条数的数据。
缺点是，不适用于结果集不以ID连续自增的分页场景。
在复杂分页场景，往往需要通过过滤条件，筛选到符合条件的ID，此时的ID是离散且不连续的。
2. join 分页方式
```sql
SELECT * FROM tbl_works t1 
JOIN (SELECT id from tbl_works WHERE status=1  limit 100000, 10) t2
ON t1.id = t2.id  // 53.6 ms
```
这条SQL的含义是，通过自连接与join定位到目标 ids，然后再将数据取出。
在定位目标 ids时，由于 SELECT的元素只有主键 ID，且status 存在索引，因此MySQL只需在索引中，就能定位到目标 ids，不用在数据文件上进行查找。
## 单表场景 limit 深度分页 总结
通过利用索引覆盖，能极大的优化了Limit分页查询的效率。
在真正的实践中，除了使用索引覆盖，优化查询速度外，我们还可以使用 Redis 缓存，将热点数据进行缓存储存。
背景描述的事故，我们考虑了时间成本和业务复杂度后，最后采取的是限制分页和增加缓存。
所谓的限制分页，即在不影响阅读体验的前提下，只允许用户可以查看前几千条的数据。
经测验，偏移量较小时的查询效率较令人满意，查询效率接近使用索引覆盖查询的速度。

## 分表场景，limit深度分页存在的严重性能问题
分表分页场景下的 分页逻辑，要从 0开始去每一个分表 获取到 limit 全部的数据， 而不是从offset 开始。为了合并之后的结果不出错，每一个分表的查询是必须0开始， 归并之后的结果才不会错。
那么要去每一个 分表 获取到 limit 全部的1000000 + 10 条 数据 ， 会导致每一个分表都走 全表扫描+ 文件排序 filesort ， 每一个分表的性能都很低。

所以， 分库分表场景， Sharding-JDBC 需要将偏移量前的记录全部取出，归并排序后，挑选最后10条记录。
这会在数据库本身就执行很慢的情况下，进一步加剧性能瓶颈。
因为原SQL仅需要传输10条记录至客户端，而改写之后的SQL则会传输1,000,010 * 2的记录至客户端。