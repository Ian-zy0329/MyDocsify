## 网络
### TCP/IP 四层模型
1. 应用层 主要提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会交给下一层传输层来传输     
   应用层常见协议：HTTP（超文本传输协议）、SMTP（简单邮件发送协议）、POP3/IMAP（邮件接收协议）、FTP（文件传输协议）、Telnet（远程登陆协议）、SSH（安全的网络传输协议）、RTP（实时传输协议）、DNS（域名管理系统）     
   HTTPS 协议，是 HTTP 的加强安全版本。HTTPS 是基于 HTTP 的，也是用 TCP 作为底层协议，并额外使用 SSL/TLS 协议用作加密和安全认证。默认端口号是 443.
2. 传输层 传输层的主要任务就是负责向两台终端设备进程之间的通信提供通用的数据传输服务。TCP（传输控制协议 ）、UDP（用户数据协议）
3. 网络层 网络层负责为分组交换网上的不同主机提供通信服务，网络层的还有一个任务就是选择合适的路由，使源主机运输层所传下来的分组，能通过网络层中的路由器找到目的主机
   网络层协议 : NAT（网络地址转换协议）、IP（网际协议）
4. 网络接口层 数据链路层和物理层的合体

### HTTP 常见状态码
2xx Success（成功状态码,200 OK）、3xx Redirection（重定向状态码）、4xx Client Error（客户端错误状态码，404 Not Found、400 Bad Request）、5xx Server Error（服务端错误状态码，500 Internal Server Error、502 Bad Gateway）

## redis
### 为什么要用 Redis？
- 传统数据库数据保存在磁盘，而 Redis 基于内存，内存的访问速度比磁盘快很多。
- 一般像 MySQL 这类的数据库的 QPS 大概都在 4k 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 5w+，甚至能达到 10w+。可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。

### Redis 除了做缓存，还能做什么？
分布式锁、限流、延时队列、通过 Bitmap 统计活跃用户、通过 Sorted Set 维护排行榜

### Redis 常用的数据类型有哪些？
- 5 种基础数据类型：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。
- 3 种特殊数据类型：HyperLogLog（基数统计）、Bitmap （位图）、Geospatial (地理位置)。

### 使用 HyperLogLog 统计页面 UV 怎么做？
- 通过'PFADD'，将访问指定页面的每个用户 ID 添加到 HyperLogLog 中。

       PFADD PAGE_1:UV USER1 USER2 ...... USERn

- 通过'PFCOUNT'统计指定页面的 UV。

      PFCOUNT PAGE_1:UV

### Redis 实现一个排行榜怎么做？
通过Redis 的 Sorted Set （有序集合），ZRANGE (从小到大排序)、 ZREVRANGE （从大到小排序）、ZREVRANK (指定元素排名)。

### Redis 单线程模型了解吗？
对于读写命令来说，Redis 一直是单线程模型。不过，在 Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作， Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）        
Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型,这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。

### 既然是单线程，那怎么监听大量的客户端连接呢？
Redis 通过 IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。       
IO多路复用（Input/Output Multiplexing）是一种在单个线程中管理多个输入/输出通道的技术。它允许一个线程同时监听多个输入流（例如网络套接字、文件描述符等），并在有数据可读或可写时进行相应的处理，而不需要为每个通道创建一个独立的线程

### Redis6.0 之前为什么不使用多线程？
- 单线程编程容易并且更容易维护；
- Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
- 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

### Redis6.0 之后为何引入了多线程？
Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

### Redis 给缓存数据设置过期时间有什么用？
内存是有限且珍贵的，如果不对缓存数据设置过期时间，那内存占用就会一直增长，最终可能会导致 OOM 问题。通过设置合理的过期时间，Redis 会自动删除暂时不需要的数据，为新的缓存数据腾出空间。

### Redis 是如何判断数据是否过期的呢？
Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。
在查询一个 key 的时候，Redis 首先检查该 key 是否存在于过期字典中（时间复杂度为 O(1)），如果不在就直接返回，在的话需要判断一下这个 key 是否过期，过期直接删除 key 然后返回 null

### Redis 过期 key 删除策略了解么？
1. 惰性删除：只会在取出/查询 key 的时候才对数据进行过期检查。这种方式对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。
2. 定期删除：周期性地随机从设置了过期时间的 key 中抽查一批，然后逐个检查这些 key 是否过期，过期就删除 key。相比于惰性删除，定期删除对内存更友好，对 CPU 不太友好。
3. 延迟队列：把设置过期时间的 key 放到一个延迟队列里，到期之后就删除 key。这种方式可以保证每个过期 key 都能被删除，但维护延迟队列太麻烦，队列本身也要占用资源。
4. 定时删除：每个设置了过期时间的 key 都会在设置的时间到达时立即被删除。这种方法可以确保内存中不会有过期的键，但是它对 CPU 的压力最大，因为它需要为每个键都设置一个定时器。

Redis 采用的是 定期删除+惰性删除 结合的策略

### Redis 内存淘汰策略了解么？（8种）
1. volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰。
2. volatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰。
2. volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰。
3. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。
4. allkeys-lru（least recently used）：从数据集（server.db[i].dict）中移除最近最少使用的数据淘汰。
5. allkeys-lfu（least frequently used）：从数据集（server.db[i].dict）中移除最不经常使用的数据淘汰。
5. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰。
6. no-eviction（默认内存淘汰策略）：禁止驱逐数据，当内存不足以容纳新写入数据时，新写入操作会报错。

allkeys-xxx 表示从所有的键值中淘汰数据，而 volatile-xxx 表示从设置了过期时间的键值中淘汰数据。

### 什么是 RDB 持久化？
Redis 可以通过创建快照来获得存储在内存里面的数据在 某个时间点 上的副本

### 什么是 AOF 持久化？
开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区 server.aof_buf 中，
然后再根据持久化方式的 （appendfsync always、appendfsync everysec、appendfsync no） 配置来决定什么时候将其同步到硬盘中的 aof 文件

### Redis 4.0 对于持久化机制做了什么优化？
Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）
如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

### RDB 和 AOF 的优缺点（区别）
- RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会比 RDB 文件大很多。
- 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。
- RDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 RDB 文件的过程是比较繁重的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。
- RDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。
- AOF 以一种易于理解和解析的格式包含所有操作的日志。

### 如何使用 Redis 事务？
Redis 可以通过 MULTI，EXEC，DISCARD 和 WATCH 等命令来实现事务(Transaction)功能。

### Redis 事务支持原子性吗？
Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的。

### Redis 事务支持持久性吗？
AOF 持久化的fsync策略为 no、everysec 时都会存在数据丢失的情况 。always 下可以基本是可以满足持久性要求的，但性能太差，实际开发过程中不会使用。因此，Redis 事务的持久性也是没办法保证的

### 如何解决 Redis 事务的缺陷？
用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。
不过，如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的，因此， 严格来说的话，通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的。

### 什么是 bigkey？有什么危害？
一个 key 对应的 value 所占用的内存比较大。
- String 类型的 value 超过 1MB
- 复合类型（List、Hash、Set、Sorted Set 等）的 value 包含的元素超过 5000 个

消耗更多的内存空间、性能造成比较大的影响，大 key 还会造成阻塞问题（客户端超时阻、网络阻塞、工作线程阻塞）
### 如何发现 bigkey？
1. 使用 Redis 自带的 --bigkeys 参数来查找。
2. 借助开源工具分析 RDB 文件。（redis-rdb-tools、rdb_bigkeys）

### 如何处理 bigkey？
1. 分割 bigkey：将一个 bigkey 分割为多个小 key。例如，将一个含有上万字段数量的 Hash 按照一定策略（比如二次哈希）拆分为多个 Hash。
2. 手动清理：Redis 4.0+ 可以使用 UNLINK 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 SCAN 命令结合 DEL 命令来分批次删除。
3. 采用合适的数据结构：例如，文件二进制数据不使用 String 保存、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）。
4. 开启 lazy-free（惰性删除/延迟释放） ：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

### 什么是 hotkey？如何发现 hotkey？
如果一个 key 的访问次数比较多且明显多于其他 key 的话，那这个 key 就可以看作是 hotkey
使用 Redis 自带的 --hotkeys 参数来查找。
### 如何解决 hotkey？
1. 读写分离：主节点处理写请求，从节点处理读请求。
2. 使用 Redis Cluster：将热点数据分散存储在多个 Redis 节点上。
3. 二级缓存：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。

### 大量 key 集中过期问题
1. 给 key 设置随机过期时间。
2. 开启 lazy-free（惰性删除）指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

### 什么是内存碎片?为什么会有 Redis 内存碎片?
你可以将内存碎片简单地理解为那些不可用的空闲内存。举个例子：操作系统为你分配了 32 字节的连续内存空间，而你存储数据实际只需要使用 24 字节内存空间，那这多余出来的 8 字节内存空间如果后续没办法再被分配存储其他数据的话，就可以被称为内存碎片。
1、Redis 存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。
2、频繁修改 Redis 中的数据也会产生内存碎片。
Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。
直接通过 config set 命令将 activedefrag 配置项设置为 yes 即可。

### 什么是缓存穿透？
缓存穿透说简单点就是⼤量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，没有经过缓存这⼀层。
- 最基本的就是⾸先做好参数校验，⼀些不合法的参数请求直接抛出异常信息返回给客户端。
- 缓存⽆效 key 如果缓存和数据库都查不到某个 key 的数据就写⼀个到 Redis 中去并设置过期时间
- 布隆过滤器 把所有可能存在的请求的值都存放在布隆过滤器中，当⽤户请求过来，先判断⽤户
  发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端
- 接口限流

### 什么是缓存雪崩？
缓存或者有⼀些被⼤量访问数据（热点缓存）在同一时间大面积失效，后面的请求直接落在数据库上，造成数据库短时间内承受大量请求。
针对 Redis 服务不可⽤的情况：
1. Redis 集群：采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。Redis Cluster 和 Redis Sentinel 是两种最常用的 Redis 集群实现方案。
2. 多级缓存：设置多级缓存，例如本地缓存+Redis 缓存的二级缓存组合，当 Redis 缓存出现问题时，还可以从本地缓存中获取到部分数据。

针对大量缓存同时失效的情况：
1. 设置随机失效时间（可选）：为缓存设置随机的失效时间，例如在固定过期时间的基础上加上一个随机值，这样可以避免大量缓存同时到期，从而减少缓存雪崩的风险。
2. 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。
3. 持久缓存策略（看情况）：虽然一般不推荐设置缓存永不过期，但对于某些关键性和变化不频繁的数据，可以考虑这种策略。

### 如何保证缓存和数据库数据的一致性？（缓存常用的 3 种读写策略）
1. Cache Aside Pattern（旁路缓存模式） 写： 先更新 db ，然后直接删除 cache 。读：从 cache 中读取数据，读取到就直接返回，cache 中读取不到的话，就从 db 中读取数据返回，再把数据放到 cache 中。
2. Read/Write Through Pattern（读写穿透）写：先查 cache，cache 中不存在，直接更新 db。cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（同步更新 cache 和 db）。读：从 cache 中读取数据，读取到就直接返回。读取不到的话，先从 db 加载，写入到 cache 后返回响应。
3. Write Behind Pattern（异步缓存写入）Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。

### 如何保证 Redis 服务高可用？
Redis Sentinel（哨兵） 集群
在 redis 主从复制的集群下，哨兵监控 redis 节点的运行状态，当 master 节点故障时，根据一定的规则选出一个 slave 节点升级为 master ，确保 redis 系统的可用性
### Sentinel（哨兵）有什么左右？
1. 监控
2. 故障转移
3. 通知
4. 配置提供

### redis 缓存数据量太大怎么办？
Redis Cluster
Redis 切片集群就是部署多台主节点（master），这些节点平等没有主从之说，同时对外提供读写服务，缓存的数据库相对均匀的分布在这些 redis 实例上，客户端的请求通过路由规则转发到目标 master 上。

## Elasticsearch

### Elasticsearch 是什么？
Elasticsearch 是一个开源的、Restful 搜索和分析引擎，可以用来解决数据库进行模糊搜索时存在的性能问题，适用于所有类型的数据，包括文本、数字、地理空间、结构化和非结构化数据。

### 倒排索引是什么？
倒排索引是用于提高数据检索速度的数据结构，倒排索引首先将检索文档进行分词得到多个词语/词条，然后将词语和包含该词语的文档id关联，从而提高检索效率。      
分词就是对一段文本，通过规则和算法分出多个词，每个词作为搜索的最细颗粒度。分词的目的是为了搜索，尤其是在数据量大的情况下，分词的实现可以快速、高效的筛选出相关性高的文档内容

### 倒排索引的创建和检索流程？
创建：
1. 建立文档列表，每个文档都有一个唯一的文档id与之对应
2. 通过分词器将文档分词，生成类似 '<词语,文档id>' 的一组组数据
3. 将词语作为索引关键字，记录下词语和文档的关系，也就是哪些文档包含该词语

检索：
1. 根据分词查找对应的文档id
2. 根据文档id找到文档

### 倒排索引由什么组成？
- 单词字典：用于储存单词列表，一般用 B+树或者 Hash 拉链法储存，提高查询效率
- 倒排列表：记录单词对应的文档集合：
  - DocId：文档ID
  - TF：单词出现频率，即词频
  - Position：单词在文档中出现的位置，用于检索
  - Offset：偏移量，记录单词开始结束位置，用于高亮显示

### 分词器有什么作用？
分词器是搜索引擎的一个核心组件，负责对文档内容进行分词，也就是将一个文档转换成单词词典，单词词典是文档中出现过的所有单词构成的字符串集合，分词器有很多种，不同分词器的分词逻辑可能不同

### 常用分词器有哪些？
非中文分词器：
- Standard Analyzer：标准分词器，也是默认分词器，英文转换成小写，中文只支持单字切分
- Simple Analyzer：简单分词器，通过非字母字符来分割文本信息，英文大写转小写，非英文不进行分词
中文分词器：
- IK Analyzer：最常用的开源中文分词器，包括两种分词模式：ik_max_word：细粒度切分模式，会将文本做最细粒度的拆分，尽可能多的拆分出词语。ik_smart：智能模式，会做最粗粒度的拆分，已被分出的词语将不会再次被其他词语占有
- Ansj：基于 n-Gram+CRF+HMM 的中文分词的 Java 实现，分词速度达到每秒钟大约 200 万字左右，准确率能达到 96% 以上，实现了中文分词、中文姓名识别、用户自定义词典、关键字提取、自动摘要、关键字标记等功能。
其他分词器：
- Keyword Analyzer：关键词分词器，输入文本等于输出文本

### 分词器由什么组成？
分词器由三种组件组成：
- Character Filters：处理原始文本，例如取出 HTML 标签
- Tokenizer：按分词器规则切分单词
- Token Filters：对切分后的单词加工，包括转小写，切除停用词，添加近义词

### Elasticsearch 如何基于拼音搜索？
可以使用拼音分词器，拼音分词器用于汉字和拼音之间的转换

### keyword 和 text 有什么区别？
keyword 不走分词器，text 会走分词器，使用 keyword 关键字查询效率更高

### Elasticsearch 有否有数组类型？
没有专门的数组数据类型，默认情况下，任何字段都可以包含零个或多个值，但是，数组中的所有值必须具有相同的数据类型

### Elasticsearch 怎么修改索引字段类型
在生产中，我们不要直接使用索引的正式索引名，我们建索引feh-product-sit-v1并给他配置一个别名feh-product-sit-alias，代码配置文件中就使用 feh-product-sit-alias,去操作es，如果遇到这种情况，我们就直接新建一个索引feh-product-sit-v2，然后按照上面的方式重推数据后，将索引feh-product-sit-v1去除别名 feh-product-sit-alias的同时将feh-product-sit-v2别名为 feh-product-sit-alias,

        POST /_aliases
        {
            "actions": [{
                    "add": {
                         "index": "index-new",
                         "alias": "index-alias"
                    }
                },
                {
                    "remove": {
                        "index": "index-old",
                        "alias": "index-alias"
                    }
                }
            ]
        }

这样有个好处，如上是一条命令进行的原子性操作，可以减少在删除旧索引和切换新索引操作时带来的影响

### 什么是 Nested 数据类型？有什么用？
Nested 数据类型可以避免 数组扁平化处理，多个数组的字段会做笛卡尔积，导致查询出不存在的数据
如果需要索引对象数组并且保持数组中每个对象的独立性，要使用 Nested 数据类型而不是对象数据类型

### 什么是 Mapping？
Mapping 定义字段名称、数据类型、优化信息（比如是否索引）、分词器，一个 Index 对应一个 Mapping

### 有自定义过 Mapping 吗？你是这么做的？
1. 创建临时 Index，插入一些临时数据；
2. 访问 Mapping API，获取相关 Mapping 定义；
3. 在此基础上进行修改，如添加 keyword，nested 类型；
4. 删除临时 Index

### 动态 Mapping 有几种属性配置？
- dynamic = true：新字段被添加到映射中（默认）
- dynamic = runtime：新字段作为运行时字段添加到映射中，这些字段未编入索引，并_source在查询时加载
- dynamic = false：新字段将被忽略，这些字段不会被索引或可搜索
- dynamic = strict：如果检测到新字段，则会抛出异常并拒绝文档，新字段必须显式添加到映射中

### 动态 Mapping 如何防止字段无限增加
通过映射限制设置来限制字段映射的数量并防止映射爆炸
- index.mapping.total_fields.limit：限制了索引中的字段最大数量。字段、对象映射以及字段别名计入此限制，默认值为 1000。
- index.mapping.depth.limit：字段最大深度 默认 20
- index.mapping.nested_fields.limit：nested 索引中不同映射的最大数量，默认 50
- index.mapping.nested_objects.limit：单个文档可以包含的嵌套 JSON 对象，默认 10000
- index.mapping.field_name_length.limit：设置字段名称的最大长度，默认 Long.MAX_VALUE（无限制）
- index.mapping.dimension_fields.limit：索引的最大时间序列维度数，默认 16

### Term 查询和全文检索区别？
term 查询条件不做分词处理，只有查询词和文档中的词精确匹配才会被搜索到，一般用于非文本字段查询。
全文检索一般用于文本查询，会使用对应分词器，步骤为：分词、词项逐个查询、汇总多个词项得分

### 如何实现范围查询？
range 查询用于匹配在某一范围内的数值型、日期类型或者字符串型字段的文档，。
range 查询支持的参数有以下几种：gt 大于、gte 大于等于、lt 小于、lte 小于等于

### match 和 match_phrase 区别？
match 查询多个检索词之间默认是 or 关系，match_phrase 查询多个检索词之间默认是 and 关系

### Multi match 有几种匹配策略，有什么区别？
Multi match 用于但条件多字段查询：
- best_fields（默认）：查询结果包含任一查询条件，但最终得分为最佳匹配字段得分
- most_fields：查询结果包含任一查询条件，但最终得分合并所有匹配字段得分，默认查询条件之间是 or 连接
- cross_fields：跨字段匹配，解决了 most_fields 查询词无法使用 and 连接的问题，匹配更加精确， and 相当于整合多个字段为一个字段，但又不想 copy_to 占用存储空间

### ES 怎么查看具体的分数来源？
在查询种设置参数'"explain":true'  

### ES 相关性算法有哪些？
ES 5.0 之前默认的相关性算法是 TF-IDF，之后的默认采用 BM25
与BM25算法相比，TF-IDF算法没有考虑文档长度和查询长度的影响，因此在处理长文档和短查询时可能会出现评分偏低的问题。但是TF-IDF算法计算速度较快，并且在处理短文本和长查询时表现较好。

### bool 查询有几种查询子句？
- must：结果必须匹配 must 查询条件，贡献算分
- should：结果应该匹配 should 子句查询的一个或多个，贡献算分
- must_not：结果必须不能匹配该查询条件
- filter：结果必须匹配该过滤条件，但不计算得分，可提高查询效率

### ES 和 MySQL 同步策略有哪些？
同步类型分为 全量同步和增量同步
- 全量同步即建好 Elasticsearch 索引后一次性导入 MySQL 所有数据，全量同步工具有：go-mysql-elasticsearch，DataX
- 增量同步即对 MySQL 中新增、修改、删除的数据进行同步
  - binlog 同步组件 Canal（推荐）：使用 Canal 可以做到业务代码完全解耦，API 完全解耦，零代码实现准实时同步，Canal 通过解析 MySQL 的 binlog 日志文件进行数据同步 
  - 同步双写：修改数据时同步到 es
  - 异步双写：修改数据时，使用 MQ 异步写入 es
  - 定时器：定时同步数据到 es

### Canal 增量数据同步 es 的原理？
1. Canal 模拟 MySQL Slave 节点与 MySQL Master 节点的交互协议，把自己伪装成一个 MySQL Slave 节点，向 MySQL Master 节点请求 binlog
2. MySQL Master 节点接收到请求后，根据偏移量将新的 binlog 发送给 MySQL Slave 节点
3. Canal 接收到 binlog 之后，对日志进行解析，获取主库的结构及数据变更

### es 集群中的节点角色有哪些？
- 主节点（Master-eligible node）：集群层面的管理，例如创建或删除索引、跟踪哪些节点是集群的一部分，以及决定将哪些分片分配给哪些节点。
  - 专用备选主节点（Dedicated master-eligible node）：只能作为主节点的节点，保障稳定性
  - 仅投票主节点（Voting-only master-eligible node）：仅参与主节点选举投票，不会被选为主节点
- 数据节点（data node）：数据存储和数据处理比如 CRUD、搜索、聚合
- 预处理节点（ingest node）：执行由预处理管道组成的预处理任务
- 仅协调节点（coordinating only node）：路由分发请求、聚集搜索或聚合结果
- 远程节点（Remote-eligible node）：跨集群检索或跨集群复制

### 分片是什么？
分片（shard）是集群数据的容器，索引（index）被分为多个文档碎片存储在分片中，分片又被分配到集群内的各个节点里。
当需要查询一个文档时，需要先找到其位于的分片，也就是说，分片是 es 在集群内分发数据的单位。

一个分片可以是主分片（Primary Shard）或者 副本分片（Replica Shard）。一个副本分片只是一个主分片的拷贝。
副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。

写索引数据的时候，只能在主分片上，然后再同步到副本分片。

当主分片出现问题时，会从可用的副本分片中选举一个新的主分片。

从 es 版本 7 开始，每个索引的主分片数量的默认值为 1，默认的副本分片数为 0。

### 查询文档时如何找到对应的分片？
当一个请求到达仅协调节点后，仅协调节点会根据路由公式计算出目标分片，然后再将请求转发到目标分片的主分片节点上。

### 为什么不建议使用默认的分片策略？
- 读多写少的场景：通过减少主分片和增加副本分片来提高读吞吐量
- 写多读少的场景：通过增加主分片和减少副本分片来提高写入性能

### es 集群健康状态有哪几种？
1. GREEN（健康状态）：主分片和副本分片都可用
2. YELLOW（预警状态）：主分片都可用，但存在副本分片不可用
3. RED（异常状态）：存在不可用的主分片，搜索结果可能会不完整

### es 索引优化策略有哪些？
1. 有大量写任务时，通过 Bulk 进行批量写入
2. 某些业务场景下减少副本数量，提高写入索引效率
3. es 在写入数据的时候，采用延迟写入的策略
...

### es 查询优化策略？
1. 建立冷热索引库
2. 自定义路由规则，让某一类型的文档都被存储到统一分片
3. 使用 keyword 数据类型
4. 增加副本分片提高查询吞吐量
...