## MySQL
### 事务
事务4大特性：一致性和持久性（重做日志）、原子性（回滚日志）、隔离性（锁）、
#### 事务隔离级别
| 隔离级别 | 脏读 | 不可重复读 | 幻读 | 实现方式 |
|---------|------|------------|------|---------|
| 读未提交 | ❌   | ❌         | ❌   | 无锁    |
| 读已提交 | ✅   | ❌         | ❌   | 快照读  |
| 可重复读 | ✅   | ✅         | ❌   | MVCC+间隙锁 |
| 串行化   | ✅   | ✅         | ✅   | 完全加锁 |

#### 默认隔离级别-RR
- 通过 MVCC 解决快照读幻读问题
- 通过 Gap Lock + Next-Key Lock 解决当前读幻读问题
#### 锁机制
| 锁类型 | 级别 | 描述 |
|--------|------|------|
| 共享/排它锁   | 行级 | 锁定单行记录 |
| 意向锁   | 表级 | 锁定整张表 |
| 间隙锁 |行级  | 锁定一个区间 |
| 记录锁 |  行级| 锁定一个行记录 |
| Next-key Lock |  行级| Record Lock和Gap Lock的结合。可解决幻读 |
---
#### MVCC
InnoDB的MVCC,是通过在每行记录后面保存系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID。这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的，防止幻读的产生。
1. MVCC手段只适用于Msyql隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）.
2. Read uncimmitted由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC.
3. 简单的select快照度不会加锁，删改及select for update等需要当前读的场景会加锁
原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。客观上，mysql使用的是乐观锁的一整实现方式，就是每行都有版本号，保存时根据版本号决定是否成功。Innodb的MVCC使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行所有快照连接起来。

版本链

在InnoDB引擎表中，它的聚簇索引记录中有两个必要的隐藏列：
trx_id、roll_pointer
这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id。
每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本)
每次修改都会在版本链中记录。SELECT可以去版本链中拿记录，这就实现了读-写，写-读的并发执行，提升了系统的性能。
### 索引
#### 存储引擎对比
| 特性 | InnoDB | MyISAM |
|------|--------|--------|
| 锁粒度 | 行锁 | 表锁 |
| 事务 | 支持 | 不支持 |
| 外键 | 支持 | 不支持 |
| 索引类型 | 聚簇 | 非聚簇 |

#### B+树索引优势
1. 多路平衡查找树，减少IO次数
2. 叶子节点形成链表，适合范围查询
3. 非叶子节点只存索引，可容纳更多键值

#### 索引优化原则
- 最左前缀匹配原则
- 避免在索引列上使用函数
- 优先使用覆盖索引
- 索引列区分度高

---

### SQL查询
#### SQL执行过程
1. 建立连接
2. 查询缓存(8.0前)
3. 解析器生成解析树
4. 优化器生成执行计划
5. 执行引擎执行SQL

#### Explain关键指标
| 指标 | 说明 | 优化建议 |
|------|------|---------|
| type | 访问类型 | ALL→index→range→ref→const |
| key | 使用索引 | 检查索引有效性 |
| rows | 扫描行数 | 添加合适索引 |
| Extra | 附加信息 | 避免Using filesort/temporary |

#### 回表查询和覆盖索引
普通索引（唯一索引+联合索引+全文索引）需要扫描两遍索引树  
（1）先通过普通索引定位到主键值id=5；  
（2）在通过聚集索引定位到行记录；  
这就是所谓的回表查询，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。  
覆盖索引：主键索引==聚簇索引==覆盖索引  
如果where条件的列和返回的数据在一个索引中，那么不需要回查表，那么就叫覆盖索引。   
实现覆盖索引：常见的方法是，将被查询的字段，建立到联合索引里去。

#### sql优化
索引优化：   
1. 最左前缀索引：like只用于'string%'，语句中的=和in会动态调整顺序  
2. 唯一索引：唯一键区分度在0.1以上  
3. 无法使用索引：!= 、is null 、 or、>< 、（5.7以后根据数量自动判定）in 、not in  
4. 联合索引：避免select * ，查询列使用覆盖索引

语句优化：
1. char固定长度查询效率高，varchar第一个字节记录数据长度
2. 应该针对Explain中Rows增加索引
3. group/order by字段均会涉及索引
4. Limit中分页查询会随着start值增大而变缓慢，通过子查询+表连接解决
5. count会进行全表扫描，如果估算可以使用explain 
6. delete删除表时会增加大量undo和redo日志， 确定删除可使用trancate

### 集群
#### 主从复制过程

MySQl主从复制：  

原理：将主服务器的binlog日志复制到从服务器上执行一遍，达到主从数据的一致状态。  
过程：从库开启一个I/O线程，向主库请求Binlog日志。主节点开启一个binlog dump线程，检查自己的二进制日志，并发送给从节点；从库将接收到的数据保存到中继日志（Relay log）中，另外开启一个SQL线程，把Relay中的操作在自身机器上执行一遍  
优点：作为备用数据库，并且不影响业务，可做读写分离，一个写库，一个或多个读库，在不同的服务器上，充分发挥服务器和数据库的性能，但要保证数据的一致性

binlog记录格式：statement、row、mixed
基于语句statement的复制、基于行row的复制、基于语句和行（mix）的复制。其中基于row的复制方式更能保证主从库数据的一致性，但日志量较大，在设置时考虑磁盘的空间问题。


#### 数据一致性问题

"主从复制有延时"，这个延时期间读取从库，可能读到不一致的数据。    
- 缓存记录写key法：  
在cache里记录哪些记录发生过的写请求，来路由读主库还是读从库
- 异步复制：  
在异步复制中，主库执行完操作后，写入binlog日志后，就返回客户端，这一动作就结束了，并不会验证从库有没有收到，完不完整，所以这样可能会造成数据的不一致。
- 半同步复制：  
当主库每提交一个事务后，不会立即返回，而是等待其中一个从库接收到Binlog并成功写入Relay-log中才返回客户端，通过一份在主库的Binlog，另一份在其中一个从库的Relay-log，可以保证了数据的安全性和一致性。
- 全同步复制：  
指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。

### 面试题
#### 分库分表
如何进行分库分表    
分表用户id进行分表，每个表控制在300万数据。    
分库根据业务场景和地域分库，每个库并发不超过2000  

Sharding-jdbc 这种 client 层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是各个系统都需要耦合 Sharding-jdbc 的依赖，升级比较麻烦  
Mycat 这种 proxy 层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了 

水平拆分：一个表放到多个库，分担高并发，加快查询速度
- id保证业务在关联多张表时可以在同一库上操作
- range方便扩容和数据统计
- hash可以使得数据更加平均

垂直拆分：一个表拆成多个表，可以将一些冷数据拆分到冗余库中
不是写瓶颈优先进行分表
- 分库数据间的数据无法再通过数据库直接查询了。会产生深分页的问题
- 分库越多，出现问题的可能性越大，维护成本也变得更高。
- 分库后无法保障跨库间事务，只能借助其他中间件实现最终一致性。

分库首先需考虑满足业务最核心的场景：
1、订单数据按用户分库，可以提升用户的全流程体验
2、超级客户导致数据倾斜可以使用最细粒度唯一标识进行hash拆分
3、按照最细粒度如订单号拆分以后，数据库就无法进行单库排重了


三个问题：
富查询：采用分库分表之后，如何满足跨越分库的查询？使用ES的宽表
借助分库网关+分库业务虽然能够实现多维度查询的能力，但整体上性能不佳且对正常的写入请求有一定的影响。业界应对多维度实时查询的最常见方式便是借助 ElasticSearch；  
数据倾斜：数据分库基础上再进行分表；
分布式事务：跨多库的修改及多个微服务间的写操作导致的分布式事务问题？  
深分页问题：按游标查询，或者叫每次查询都带上上一次查询经过排序后的最大 ID；

#### 如何将老数据进行迁移
双写不中断迁移
- 线上系统里所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改；
- 系统部署以后，还需要跑程序读老库数据写新库，写的时候需要判断updateTime；
- 循环执行，直至两个库的数据完全一致，最后重新部署分库分表的代码就行了；

#### 如何生成自增的 ID 主键
- 使用 redis 可以生成分布式系统自增 ID
- 并发不高可以单独起一个服务，生成自增 ID
- 设置数据库 step 自增步长可以支撑水平伸缩
- UUID 适合文件名、编号，但是不适合做主键
- snowflake 雪花算法，综合了 41 时间（ms）、10机器、12序列号（ms内自增）