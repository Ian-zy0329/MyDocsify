## 滴滴金融外包
### 自我介绍

### 描述在电商系统具体做了什么
负责后端开发，参与商品模块、订单模块开发
商品模块负责综合商品搜索、相关商品推荐、聚合商品信息搜索的功能实现，主要用到了 es，
订单模块负责订单的生成、取消、超时取消等功能的实现，主要用到 mysql、redis、lua脚本
elk日志系统搭建，
项目后期与前端的联调测试

### 用 mq 中遇到过什么问题
1. 消息重复消费问题
   "在使用 MQ 的过程中，我遇到过消息重复消费的问题。为了避免这个问题，我在消费端引入了幂等性处理。例如，对于库存扣减操作，每条消息都有唯一的事务ID，我在数据库中记录这个ID，确保每条消息只被处理一次，即使重复投递也不会导致数据问题。通过这种方式，我们确保了系统在高并发场景下的稳定性。"
2. 消息丢失问题
   "在消息传递过程中，曾遇到过消息丢失的问题。我们通过开启消息的持久化功能来确保消息在队列中的可靠存储，此外在生产消息时加入了事务机制，只有当消息成功发送到消息队列时才提交事务，避免生产者阶段丢失消息。在消费端，我们通过手动确认消费进度，确保消息成功处理后再删除，避免消息丢失或未被消费的问题。"
3. 消息堆积问题
   "在高并发场景中，我遇到过消息堆积的问题，特别是在促销活动期间。为了应对这种情况，我采取了增加消费者实例来提升消费能力。同时，我优化了消费逻辑，将单条消息的处理变为批量处理，提升了消费效率。此外，我们还对部分低优先级的消息采用了异步批处理的方式，减少了系统的压力。这些措施有效缓解了消息堆积的问题。"
4. 消息顺序问题
   "在某些需要保证顺序的业务场景下，比如订单处理，我遇到过消息顺序错乱的问题。为了解决这个问题，我们通过消息分区（例如订单ID）将相关的消息路由到同一个消费者上，以此保证同一业务流的消息顺序。通过这种方式，我们确保了业务流程的正确执行，避免了因为消息顺序错误导致的业务逻辑问题。"
5. 消息队列的高可用性问题
   "为了确保 MQ 的高可用性，我们在生产环境中部署了 MQ 的集群模式，并配置了主从节点来实现自动故障转移。通过这种架构，即使某个节点出现故障，系统也能够快速恢复，保障了消息的正常传递和处理。此外，我们还对消息进行了持久化处理，避免因服务宕机导致消息丢失。"

### springboot 常用注解

@AutoWired 跟 @Resource什么区别 
- @Autowired 根据对象类型自动注入依赖对象
- @Resource 根据对象名称自动注入依赖对象
### 多线程池的核心参数

### 常见锁、分布式锁

### 介绍下 IOC、AOP

### 工作中遇到过什么大的挑战

### mysql什么情况下索引失效
使用 SELECT * 进行查询; SELECT * 不会直接导致索引失效（如果不走索引大概率是因为 where 查询范围过大导致的），但它可能会带来一些其他的性能问题比如造成网络传输和数据处理的浪费、无法使用索引覆盖;
创建了组合索引，但查询条件未遵守最左匹配原则;
在索引列上进行计算、函数、类型转换等操作;
以 % 开头的 LIKE 查询比如 LIKE '%abc';
查询条件中使用 OR，且 OR 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;
IN 的取值范围较大时会导致索引失效，走全表扫描(NOT IN 和 IN 的失效场景相同);
发生隐式转换open in new window;

### 事务失效

### elk日志系统是怎么实现的

### arraylist 默认长度 10

### HashMap 实现原理

### mysql 索引结构

### 总结
简单基础的东西还是不够熟 IOC、AOP概念不够熟练，mysql 不够熟

## 吉客云
### redis 通过消息队列异步更新 mysql 库存时，如果缓存过期了，或者由于消息堆积导致缓存过期，怎么处理
消息中保存了库存扣减的数量，不需要通过缓存去获取库存，缓存中的库存只是做一个校验，更新mysql库存时延迟双删掉缓存就能保证一致性
### mysql 索引、索引底层数据结构、聚集索引和非聚集索引、索引失效的场景、sql调优
### 事务失效、怎么处理
1. 方法的自我调用，当一个类中的方法调用同一个类中的另一个事务方法时，事务不会生效，导致触发不了 aop 代理，因为是直接通过 this 调用的
2. 非公共方法上的 @Transactional 注解
3. 异常没有被正确处理（未抛出或捕获）
4. @Transactional 注解没有被 Spring 管理的代理处理
5. 事务传播行为设置不当
6. 数据库不支持事务，或者存储引擎不支持事务，比如 MyASIM
### 深度分页
1. 覆盖索引 + 延迟关联（子查询优化）、游标
2. 基于索引的范围查询（跳过 OFFSET）
3. 延迟加载和用户体验优化
4. 缓存或预计算：适合经常请求的固定分页查询，将结果缓存起来，减少数据库压力。
### 线程池的参数、拒绝策略、
### 批量插入、为什么分批插入
1. 减少事务开销：通过减少事务提交的频率，降低事务管理的开销。
2. 减少网络通信次数：减少多次网络往返请求的开销，提高插入效率。
3. 避免锁竞争与长时间锁定：缩短持有锁的时间，减少对其他并发操作的影响。
4. 降低内存消耗：避免一次性插入过多数据导致内存溢出，分批插入降低内存压力。
5. 减少事务日志 I/O 开销：减少 InnoDB 的事务日志写入频率，降低磁盘 I/O 负担。
6. 避免单次操作时间过长：提高数据库的响应速度，避免长时间执行大事务。
7. 降低回滚的风险：分批插入时，发生错误时只需回滚当前批次，减少回滚开销。
### 慢接口
1. 优化代码逻辑，减少重复计算和不必要的 I/O。
2. 优化数据库查询，避免慢 SQL，使用索引、缓存等提高查询效率。
3. 使用分布式缓存减少数据库负载，解决缓存穿透、雪崩等问题。
4. 系统层面通过连接池、异步处理、网络压缩、CDN 加速等方式提升接口响应速度。
### JVM调优
### JVM内存模型
重点是堆
### JVM内存分配
1. 指针碰撞
2. 空闲列表
### 垃圾收集器
### 线上服务对外内存溢出
### java集合 lambda表达式
### 项目的收获
### 项目开发流程
### 个人优缺点
### 代码规范
### 线程死锁 

## 吉客云复试
### 项目组的结构
### 开发周期
### 在之前的项目中做了什么，有什么收获
### mysql库存更新报错，如何保持缓存和数据库一致性，数据库挂了
### 日志怎么优化，不够熟悉
问题
1. 日志存在 5--20分钟延迟
2. 日志存在丢失

分析问题
1. 对于es新写入的数据是先存放在es的内存buff中，然后通过refresh写入到操作系统的内存缓存中，写入到系统内存缓存后数据才可以被搜索到，所以延迟问题可能是由于数据积压在buff中没有进入系统缓存
2. 查看es日志发现write线程池满负荷，拒绝任务的情况，查看es的write线程池已达最大线程数，队列满了，拒绝了很多任务，对于这种情况需要优化es的线程池配置

JVM调优
1. 通过查看GC日志，发现yongGC频繁，通过jstat查看每秒GC情况，发现Eden区增长速度很快，很快就满了，可能原因就是新生代分配内存过小
2. 检查GC日志发现，新生代为512M，老年代大小是3000多M，总共堆大小是4g，JVM使用CMS收集器会自动调参，所以还是需要显式的配置堆大小和新生代大小
3. 所以新生代过小导致Eden区很快用完触发yongGC，yongGC时会停止所有工作线程，只有GC线程在进行垃圾回收，导致ES短时间的停顿，频繁的yongGC对ES性能影响较大
4. 老年代过大也会导致fullGC时间过长，GC停顿时间更长，影响es性能，也会导致客户端一定时间没有响应发生timeout，导致请求失败
5. 调整JVM堆大小，分配为系统内存一半，新生代和老年代内存分配为1：1，优化后新生代增长率显著降低，GC频率也降低了

ES调优
1. 优化 fsync，es默认每隔5s会把trans log日志数据通过fsync强制刷新到磁盘，这种方式提高了数据的安全性，但也降低了一点性能，通过设置异步刷新trans log来提高效率
2. 优化 refresh，对于日志搜索来说实时性要求不是那么高，把refresh设置为5s，降低系统开销
3. 优化线程池，用的是fixed类型线程池，线程数固定的，线程数最大也只能设置为cpu核数再加一，把队列容量加大起到削峰缓冲作用，不过也不能调太大会占用过多堆内存

控制数据源
1. 日志生成数据量过大，多是因为对于一些大数据量日志没必要上传到es，比如大数据量的列表查询接口、debug级别日志，这些就不上传到日志服务器上
### 订单超时自动取消，判断订单状态的时候如果用户正在支付，如何处理
### 死锁怎么产生，怎么解决，检查死锁的工具
### 之前薪资结构

## 宠胖胖外包
### redis 数据类型、zset使用场景
### mysql隔离等级
### spring bean 作用域
### spring事务注解、事务失效场景、事务失效怎么让它生效
### 商品模块的表、表字段
商品表（商品的基本信息、商品的促销信息、商品的属性信息、商品的关联）、商品SKU表（）、商品阶梯价格表、商品满减表、商品会员价格表、商品分类列表、商品品牌表、商品属性分类表、商品属性表、商品属性值表、
订单表、订单商品信息表、购物车表、订单退货申请表
### spu、sku概念，以及相关表
### 商品搜索的设计、es搜索的流程
### 分词过程中遇到过什么问题
1. 多语言处理问题 使用 多语言分词器（如 language 分词器）或者为不同语言字段配置不同的分词器。例如，可以为英文字段使用 Standard Analyzer，为中文字段使用 IK Analyzer。
2. 过度分词 分词器的分词粒度过细，导致词语被不必要地拆分，选择更适合的分词器，ik 两种分词模式
3. 未考虑同义词 配置 同义词过滤器（Synonym Filter），在索引时和查询时对同义词进行处理
4. 停用词未过滤 搜索时出现大量无意义的词（如 "a"、"the" 等），导致查询效率低下或查询结果不准确。使用 停用词过滤器（Stop Words Filter）在分词时自动过滤掉停用词
5. 拼写错误或变形词的处理
6. 字段混淆 不同字段使用了不同的分词器，导致查询时出现混淆。例如，某字段使用的是 keyword 类型（不分词），而查询时使用的是分词的字段，可能导致查询结果不匹配。
### 怎么实现订单超时取消
### 消费失败后续怎么处理，消费重试失败后怎么处理
1. 消息重试机制
2. 死信队列
3. 手动补偿机制
4. 幂等性保证
5. 告警机制
6. 数据库回查机制
### 库存扣减怎么防止超卖
### 库存变动如何同步到 redis
### 项目名称太模糊、上线、简历项目不够规范

项目团队、开发周期、上线时间、迭代

C2C、
开发周期：5个月左右 1、需求分析 2、系统设计，确定架构和技术方案，数据库设计、功能模块划分和API文档（一个月） 3、前后端开发阶段(三个月) 4、测试和验证(一个月) 5、部署上线
开发团队：产品经理、后端开发（十个人）、前端开发（五个人左右）、测试团队（三个）、运维（一个）

